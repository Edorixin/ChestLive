2021-01-27 10:28:06.992691: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2021-01-27 10:28:07.018525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2400000000 Hz
2021-01-27 10:28:07.021690: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe15c000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-01-27 10:28:07.021742: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-27 10:28:07.026756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-01-27 10:28:07.164802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bbdbff0c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-01-27 10:28:07.164870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 3080, Compute Capability 8.6
2021-01-27 10:28:07.166759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:d5:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2021-01-27 10:28:07.167176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-27 10:28:07.170787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-27 10:28:07.174182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-27 10:28:07.174748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-27 10:28:07.177493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-27 10:28:07.179097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-27 10:28:07.185251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-27 10:28:07.186790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-01-27 10:28:07.186839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-27 10:28:07.187704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-27 10:28:07.187717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-01-27 10:28:07.187724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-01-27 10:28:07.189210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4007 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:d5:00.0, compute capability: 8.6)
2021-01-27 10:28:28.926135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:d5:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2021-01-27 10:28:28.926215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-27 10:28:28.926229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-27 10:28:28.926243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-27 10:28:28.926254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-27 10:28:28.926274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-27 10:28:28.926287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-27 10:28:28.926299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-27 10:28:28.927374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-01-27 10:28:28.928505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:d5:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2021-01-27 10:28:28.928540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-27 10:28:28.928549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-27 10:28:28.928557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-27 10:28:28.928565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-27 10:28:28.928572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-27 10:28:28.928580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-27 10:28:28.928588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-27 10:28:28.929668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-01-27 10:28:28.929706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-27 10:28:28.929712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-01-27 10:28:28.929716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-01-27 10:28:28.930812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4007 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:d5:00.0, compute capability: 8.6)
2021-01-27 10:35:12.602011: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-27 10:53:26.455879: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256
2021-01-27 10:53:26.523016: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-01-27 10:53:27.767153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
personlist:['DengYangTao', 'HuangJiaQian', 'LiLinWei', 'BiHongLiang', 'LPY', 'HuHaiYan', 'KuangRuiLin', 'GQY']
personlist:['XueMeng', 'WuYuan', 'XZQ', 'QinDang', 'OuRunMin', 'ZhuTianLin', 'ZhuXiaoTian']
开始
batch 0: train=0.000000 test=0.333333
batch 10: train=0.333333 test=0.000000
batch 20: train=0.000000 test=0.666667
batch 30: train=0.333333 test=0.000000
batch 40: train=0.000000 test=0.333333
batch 50: train=0.333333 test=0.000000
batch 60: train=0.333333 test=0.000000
batch 70: train=0.333333 test=0.333333
batch 80: train=0.000000 test=0.000000
batch 90: train=0.333333 test=0.000000
batch 100: train=0.333333 test=0.333333
batch 110: train=0.333333 test=0.333333
batch 120: train=0.000000 test=0.333333
batch 130: train=0.333333 test=0.000000
batch 140: train=0.333333 test=0.333333
batch 150: train=0.333333 test=0.000000
batch 160: train=0.000000 test=0.000000
batch 170: train=0.333333 test=0.000000
batch 180: train=0.333333 test=0.333333
batch 190: train=0.000000 test=0.333333
batch 200: train=0.000000 test=0.333333
batch 210: train=0.333333 test=0.333333
batch 220: train=0.333333 test=0.333333
batch 230: train=0.333333 test=0.333333
batch 240: train=0.333333 test=0.333333
batch 250: train=0.000000 test=0.333333
batch 260: train=0.333333 test=0.333333
batch 270: train=0.000000 test=0.333333
batch 280: train=0.333333 test=0.333333
batch 290: train=0.333333 test=0.333333
batch 300: train=0.000000 test=0.333333
batch 310: train=0.000000 test=0.666667
batch 320: train=1.000000 test=0.333333
batch 330: train=0.333333 test=0.333333
batch 340: train=0.333333 test=0.333333
batch 350: train=0.000000 test=0.333333
batch 360: train=0.333333 test=0.333333
batch 370: train=0.333333 test=0.333333
batch 380: train=0.333333 test=0.333333
batch 390: train=0.000000 test=0.333333
batch 400: train=0.333333 test=0.666667
batch 410: train=0.000000 test=1.000000
batch 420: train=0.333333 test=0.333333
batch 430: train=1.000000 test=0.333333
batch 440: train=0.000000 test=0.333333
batch 450: train=0.333333 test=0.333333
batch 460: train=0.333333 test=1.000000
batch 470: train=0.000000 test=0.333333
batch 480: train=0.333333 test=0.000000
batch 490: train=1.000000 test=0.333333
batch 500: train=0.333333 test=0.333333
batch 510: train=0.666667 test=0.333333
batch 520: train=0.333333 test=0.333333
batch 530: train=0.333333 test=1.000000
batch 540: train=0.333333 test=0.333333
batch 550: train=0.333333 test=0.666667
batch 560: train=0.333333 test=0.333333
batch 570: train=0.333333 test=0.333333
batch 580: train=0.333333 test=0.333333
batch 590: train=1.000000 test=1.000000
batch 600: train=0.333333 test=0.333333
batch 610: train=0.333333 test=0.333333
batch 620: train=0.333333 test=0.333333
batch 630: train=0.333333 test=0.333333
batch 640: train=0.333333 test=0.333333
batch 650: train=0.333333 test=0.666667
batch 660: train=0.000000 test=0.333333
batch 670: train=0.333333 test=0.333333
batch 680: train=0.333333 test=0.333333
batch 690: train=0.333333 test=0.333333
batch 700: train=0.333333 test=0.333333
batch 710: train=0.333333 test=0.333333
batch 720: train=1.000000 test=0.000000
batch 730: train=0.333333 test=0.000000
batch 740: train=0.333333 test=0.666667
batch 750: train=0.333333 test=0.666667
batch 760: train=0.333333 test=0.333333
batch 770: train=0.333333 test=0.333333
batch 780: train=0.000000 test=0.333333
batch 790: train=0.333333 test=0.333333
batch 800: train=0.333333 test=0.333333
batch 810: train=0.333333 test=0.666667
batch 820: train=0.333333 test=0.333333
batch 830: train=0.333333 test=0.666667
batch 840: train=0.333333 test=0.333333
batch 850: train=0.000000 test=0.333333
batch 860: train=0.333333 test=0.333333
batch 870: train=0.333333 test=0.333333
batch 880: train=0.333333 test=0.666667
batch 890: train=0.333333 test=0.333333
batch 900: train=0.333333 test=0.666667
batch 910: train=0.333333 test=0.333333
batch 920: train=0.000000 test=0.000000
batch 930: train=0.333333 test=0.333333
batch 940: train=0.333333 test=0.333333
batch 950: train=0.666667 test=0.666667
batch 960: train=0.000000 test=0.333333
batch 970: train=0.333333 test=0.333333
batch 980: train=0.333333 test=0.333333
batch 990: train=0.333333 test=0.333333
batch 1000: train=0.333333 test=0.666667
batch 1010: train=0.333333 test=0.333333
batch 1020: train=0.666667 test=0.333333
batch 1030: train=0.333333 test=0.333333
batch 1040: train=0.333333 test=0.333333
batch 1050: train=0.333333 test=0.333333
batch 1060: train=0.333333 test=0.666667
batch 1070: train=0.333333 test=0.333333
batch 1080: train=0.666667 test=0.666667
batch 1090: train=0.666667 test=0.333333
batch 1100: train=0.666667 test=1.000000
batch 1110: train=0.333333 test=0.666667
batch 1120: train=0.333333 test=0.333333
batch 1130: train=0.666667 test=0.333333
batch 1140: train=0.333333 test=0.333333
batch 1150: train=0.333333 test=0.333333
batch 1160: train=0.333333 test=0.333333
batch 1170: train=0.666667 test=0.333333
batch 1180: train=0.333333 test=0.666667
batch 1190: train=0.333333 test=0.666667
batch 1200: train=0.333333 test=0.333333
batch 1210: train=0.333333 test=0.333333
batch 1220: train=0.000000 test=0.333333
batch 1230: train=0.333333 test=0.333333
batch 1240: train=0.333333 test=0.333333
batch 1250: train=0.333333 test=0.333333
batch 1260: train=0.333333 test=0.666667
batch 1270: train=0.333333 test=0.333333
batch 1280: train=0.333333 test=0.000000
batch 1290: train=0.333333 test=0.333333
batch 1300: train=0.666667 test=0.333333
batch 1310: train=0.333333 test=0.666667
batch 1320: train=0.333333 test=0.333333
batch 1330: train=0.333333 test=0.333333
batch 1340: train=0.000000 test=0.333333
batch 1350: train=0.333333 test=0.333333
batch 1360: train=0.666667 test=0.333333
batch 1370: train=0.000000 test=0.333333
batch 1380: train=0.333333 test=0.333333
batch 1390: train=0.000000 test=0.333333
batch 1400: train=0.333333 test=0.333333
batch 1410: train=0.333333 test=0.333333
batch 1420: train=0.333333 test=0.333333
batch 1430: train=0.333333 test=0.666667
batch 1440: train=0.333333 test=0.333333
batch 1450: train=0.333333 test=0.666667
batch 1460: train=0.333333 test=0.333333
batch 1470: train=0.333333 test=0.333333
batch 1480: train=0.333333 test=0.000000
batch 1490: train=0.333333 test=0.333333
batch 1500: train=0.333333 test=0.666667
batch 1510: train=0.666667 test=0.333333
batch 1520: train=0.333333 test=0.333333
batch 1530: train=0.333333 test=0.333333
batch 1540: train=0.000000 test=0.333333
batch 1550: train=0.333333 test=1.000000
batch 1560: train=0.333333 test=0.333333
batch 1570: train=0.333333 test=1.000000
batch 1580: train=0.333333 test=0.000000
batch 1590: train=0.000000 test=0.333333
batch 1600: train=0.333333 test=0.333333
batch 1610: train=0.666667 test=0.333333
batch 1620: train=0.333333 test=0.000000
batch 1630: train=0.333333 test=0.333333
batch 1640: train=0.333333 test=0.333333
batch 1650: train=0.333333 test=0.333333
batch 1660: train=0.000000 test=0.000000
batch 1670: train=0.333333 test=0.333333
batch 1680: train=0.666667 test=0.333333
batch 1690: train=0.333333 test=0.333333
batch 1700: train=0.666667 test=0.333333
batch 1710: train=0.333333 test=0.333333
batch 1720: train=0.333333 test=0.333333
batch 1730: train=0.333333 test=0.666667
batch 1740: train=0.333333 test=0.000000
batch 1750: train=0.333333 test=0.333333
batch 1760: train=0.333333 test=0.333333
batch 1770: train=0.333333 test=0.666667
batch 1780: train=0.333333 test=0.333333
batch 1790: train=0.333333 test=0.333333
batch 1800: train=0.333333 test=0.333333
batch 1810: train=0.333333 test=0.333333
batch 1820: train=0.333333 test=0.333333
batch 1830: train=0.333333 test=0.333333
batch 1840: train=0.333333 test=0.333333
batch 1850: train=0.333333 test=0.333333
batch 1860: train=0.333333 test=0.333333
batch 1870: train=0.000000 test=0.333333
batch 1880: train=0.333333 test=0.666667
batch 1890: train=0.333333 test=0.333333
batch 1900: train=0.000000 test=0.333333
batch 1910: train=0.333333 test=0.333333
batch 1920: train=0.333333 test=0.333333
batch 1930: train=0.333333 test=0.000000
batch 1940: train=0.333333 test=0.333333
batch 1950: train=0.333333 test=0.333333
batch 1960: train=0.666667 test=0.333333
batch 1970: train=0.333333 test=0.666667Using TensorFlow backend.
/home/xuemeng/Proj/ChestMotion/ReadData.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  nda = np.array(data).shape[0]
train.py:252: RuntimeWarning: invalid value encountered in subtract
  (new_vars[var] - old_vars[var]) * cur_meta_step_size)

batch 1980: train=0.333333 test=0.333333
batch 1990: train=0.333333 test=0.333333
personlist:['XueMeng', 'WuYuan', 'XZQ', 'QinDang', 'OuRunMin', 'ZhuTianLin', 'ZhuXiaoTian']
keys:['ZhuXiaoTian', 0, 0]
keys:['ZhuXiaoTian', 'ZhuTianLin', 0]
keys:['ZhuXiaoTian', 'ZhuTianLin', 'OuRunMin']
45
135
<BatchDataset shapes: ((None, 2000, 39, 1), (None,)), types: (tf.float32, tf.float32)>
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
label:ZhuXiaoTian,  抽取出来的总次数:45,  其中预测正确的次数:45,  acc:100.0%
label:ZhuTianLin,  抽取出来的总次数:45,  其中预测正确的次数:0,  acc:0.0%
label:OuRunMin,  抽取出来的总次数:45,  其中预测正确的次数:0,  acc:0.0%
