2021-01-28 15:16:44.843199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-28 15:16:46.819787: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-01-28 15:16:46.829743: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-28 15:16:46.834567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-01-28 15:16:46.896351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:d5:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2021-01-28 15:16:46.896452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-28 15:16:46.900402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-28 15:16:46.900526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-28 15:16:46.902007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-28 15:16:46.902335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-28 15:16:46.907003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-28 15:16:46.908376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-01-28 15:16:46.908623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-28 15:16:46.910445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-01-28 15:16:46.910493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-28 15:16:47.754273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-28 15:16:47.754387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-01-28 15:16:47.754402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-01-28 15:16:47.758537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8014 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:d5:00.0, compute capability: 8.6)
2021-01-28 15:17:18.466854: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-28 15:17:18.468147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:d5:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2021-01-28 15:17:18.468213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-28 15:17:18.468289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-28 15:17:18.468307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-28 15:17:18.468329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-28 15:17:18.468348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-28 15:17:18.468378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-28 15:17:18.468398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-01-28 15:17:18.468415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-28 15:17:18.469700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-01-28 15:17:18.470025: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-28 15:17:18.470748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:d5:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2021-01-28 15:17:18.470784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-01-28 15:17:18.470816: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-28 15:17:18.470831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-28 15:17:18.470845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-28 15:17:18.470860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-28 15:17:18.470875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-28 15:17:18.470889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-01-28 15:17:18.470904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-28 15:17:18.472151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-01-28 15:17:18.472239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-28 15:17:18.472248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-01-28 15:17:18.472257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-01-28 15:17:18.473593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8014 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:d5:00.0, compute capability: 8.6)
2021-01-28 15:17:19.054287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-01-28 15:17:22.260011: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2021-01-28 15:17:22.390104: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-01-28 15:17:24.533609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-01-28 15:17:25.579498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-01-28 15:17:33.306475: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2021-01-28 15:18:41.605910: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-01-28 15:18:41.626255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz
personlist:['DengYangTao', 'HuangJiaQian', 'LiLinWei', 'BiHongLiang', 'LPY', 'HuHaiYan', 'KuangRuiLin', 'GQY']
personlist:['XueMeng', 'WuYuan', 'XZQ', 'QinDang', 'OuRunMin', 'ZhuTianLin', 'ZhuXiaoTian']
开始
batch 0: train=0.333333 test=0.333333
batch 10: train=0.333333 test=0.333333
batch 20: train=0.333333 test=0.333333
batch 30: train=0.333333 test=0.333333
batch 40: train=0.333333 test=0.333333
batch 50: train=0.333333 test=0.333333
batch 60: train=0.333333 test=0.333333
batch 70: train=0.333333 test=0.333333
batch 80: train=0.333333 test=0.333333
batch 90: train=0.333333 test=0.333333
batch 100: train=0.333333 test=0.333333
batch 110: train=0.333333 test=0.333333
batch 120: train=0.333333 test=0.333333
batch 130: train=0.333333 test=0.333333
batch 140: train=0.333333 test=0.333333
batch 150: train=0.333333 test=0.333333
batch 160: train=0.333333 test=0.333333
batch 170: train=0.333333 test=0.333333
batch 180: train=0.333333 test=0.333333
batch 190: train=0.333333 test=0.333333
batch 200: train=0.333333 test=0.333333
batch 210: train=0.333333 test=0.333333
batch 220: train=0.333333 test=0.333333
batch 230: train=0.333333 test=0.333333
batch 240: train=0.333333 test=0.333333
batch 250: train=0.333333 test=0.333333
batch 260: train=0.333333 test=0.333333
batch 270: train=0.333333 test=0.333333
batch 280: train=0.333333 test=0.333333
batch 290: train=0.333333 test=0.333333
batch 300: train=0.333333 test=0.333333
batch 310: train=0.333333 test=0.333333
batch 320: train=0.333333 test=0.333333
batch 330: train=0.333333 test=0.333333
batch 340: train=0.333333 test=0.333333
batch 350: train=0.333333 test=0.333333
batch 360: train=0.333333 test=0.333333
batch 370: train=0.333333 test=0.333333
batch 380: train=0.333333 test=0.333333
batch 390: train=0.333333 test=0.333333
batch 400: train=0.333333 test=0.333333
batch 410: train=0.333333 test=0.333333
batch 420: train=0.333333 test=0.333333
batch 430: train=0.333333 test=0.333333
batch 440: train=0.333333 test=0.333333
batch 450: train=0.333333 test=0.333333
batch 460: train=0.333333 test=0.333333
batch 470: train=0.333333 test=0.333333
batch 480: train=0.333333 test=0.333333
batch 490: train=0.333333 test=0.333333
batch 500: train=0.333333 test=0.333333
batch 510: train=0.333333 test=0.333333
batch 520: train=0.333333 test=0.333333
batch 530: train=0.333333 test=0.333333
batch 540: train=0.333333 test=0.333333
batch 550: train=0.333333 test=0.333333
batch 560: train=0.333333 test=0.333333
batch 570: train=0.333333 test=0.333333
batch 580: train=0.333333 test=0.333333
batch 590: train=0.333333 test=0.333333
batch 600: train=0.333333 test=0.333333
batch 610: train=0.333333 test=0.333333
batch 620: train=0.333333 test=0.333333
batch 630: train=0.333333 test=0.333333
batch 640: train=0.333333 test=0.333333
batch 650: train=0.333333 test=0.333333
batch 660: train=0.333333 test=0.333333
batch 670: train=0.333333 test=0.333333
batch 680: train=0.333333 test=0.333333
batch 690: train=0.333333 test=0.333333
batch 700: train=0.333333 test=0.333333
batch 710: train=0.333333 test=0.333333
batch 720: train=0.333333 test=0.333333
batch 730: train=0.333333 test=0.333333
batch 740: train=0.333333 test=0.333333
batch 750: train=0.333333 test=0.333333
batch 760: train=0.333333 test=0.333333
batch 770: train=0.333333 test=0.333333
batch 780: train=0.333333 test=0.333333
batch 790: train=0.333333 test=0.333333
batch 800: train=0.333333 test=0.333333
batch 810: train=0.333333 test=0.333333
batch 820: train=0.333333 test=0.333333
batch 830: train=0.333333 test=0.333333
batch 840: train=0.333333 test=0.333333
batch 850: train=0.333333 test=0.333333
batch 860: train=0.333333 test=0.333333
batch 870: train=0.333333 test=0.333333
batch 880: train=0.333333 test=0.333333
batch 890: train=0.333333 test=0.333333
batch 900: train=0.333333 test=0.333333
batch 910: train=0.333333 test=0.333333
batch 920: train=0.333333 test=0.333333
batch 930: train=0.333333 test=0.333333
batch 940: train=0.333333 test=0.333333
batch 950: train=0.333333 test=0.333333
batch 960: train=0.333333 test=0.333333
batch 970: train=0.333333 test=0.333333
batch 980: train=0.333333 test=0.333333
batch 990: train=0.333333 test=0.333333
batch 1000: train=0.333333 test=0.333333
batch 1010: train=0.333333 test=0.333333
batch 1020: train=0.333333 test=0.333333
batch 1030: train=0.333333 test=0.333333
batch 1040: train=0.333333 test=0.333333
batch 1050: train=0.333333 test=0.333333
batch 1060: train=0.333333 test=0.333333
batch 1070: train=0.333333 test=0.333333
batch 1080: train=0.333333 test=0.333333
batch 1090: train=0.333333 test=0.333333
batch 1100: train=0.333333 test=0.333333
batch 1110: train=0.333333 test=0.333333
batch 1120: train=0.333333 test=0.333333
batch 1130: train=0.333333 test=0.333333
batch 1140: train=0.333333 test=0.333333
batch 1150: train=0.333333 test=0.333333
batch 1160: train=0.333333 test=0.333333
batch 1170: train=0.333333 test=0.333333
batch 1180: train=0.333333 test=0.333333
batch 1190: train=0.333333 test=0.333333
batch 1200: train=0.333333 test=0.333333
batch 1210: train=0.333333 test=0.333333
batch 1220: train=0.333333 test=0.333333
batch 1230: train=0.333333 test=0.333333
batch 1240: train=0.333333 test=0.333333
batch 1250: train=0.333333 test=0.333333
batch 1260: train=0.333333 test=0.333333
batch 1270: train=0.333333 test=0.333333
batch 1280: train=0.333333 test=0.333333
batch 1290: train=0.333333 test=0.333333
batch 1300: train=0.333333 test=0.333333
batch 1310: train=0.333333 test=0.333333
batch 1320: train=0.333333 test=0.333333
batch 1330: train=0.333333 test=0.333333
batch 1340: train=0.333333 test=0.333333
batch 1350: train=0.333333 test=0.333333
batch 1360: train=0.333333 test=0.333333
batch 1370: train=0.333333 test=0.333333
batch 1380: train=0.333333 test=0.333333
batch 1390: train=0.333333 test=0.333333
batch 1400: train=0.333333 test=0.333333
batch 1410: train=0.333333 test=0.333333
batch 1420: train=0.333333 test=0.333333
batch 1430: train=0.333333 test=0.333333
batch 1440: train=0.333333 test=0.333333
batch 1450: train=0.333333 test=0.333333
batch 1460: train=0.333333 test=0.333333
batch 1470: train=0.333333 test=0.333333
batch 1480: train=0.333333 test=0.333333
batch 1490: train=0.333333 test=0.333333
batch 1500: train=0.333333 test=0.333333
batch 1510: train=0.333333 test=0.333333
batch 1520: train=0.333333 test=0.333333
batch 1530: train=0.333333 test=0.333333
batch 1540: train=0.333333 test=0.333333
batch 1550: train=0.333333 test=0.333333
batch 1560: train=0.333333 test=0.333333
batch 1570: train=0.333333 test=0.333333
batch 1580: train=0.333333 test=0.333333
batch 1590: train=0.333333 test=0.333333
batch 1600: train=0.333333 test=0.333333
batch 1610: train=0.333333 test=0.333333
batch 1620: train=0.333333 test=0.333333
batch 1630: train=0.333333 test=0.333333
batch 1640: train=0.333333 test=0.333333
batch 1650: train=0.333333 test=0.333333
batch 1660: train=0.333333 test=0.333333
batch 1670: train=0.333333 test=0.333333
batch 1680: train=0.333333 test=0.333333
batch 1690: train=0.333333 test=0.333333
batch 1700: train=0.333333 test=0.333333
batch 1710: train=0.333333 test=0.333333
batch 1720: train=0.333333 test=0.333333
batch 1730: train=0.333333 test=0.333333
batch 1740: train=0.333333 test=0.333333
batch 1750: train=0.333333 test=0.333333
batch 1760: train=0.333333 test=0.333333
batch 1770: train=0.333333 test=0.333333
batch 1780: train=0.333333 test=0.333333
batch 1790: train=0.333333 test=0.333333
batch 1800: train=0.333333 test=0.333333
batch 1810: train=0.333333 test=0.333333
batch 1820: train=0.333333 test=0.333333
batch 1830: train=0.333333 test=0.333333
batch 1840: train=0.333333 test=0.333333
batch 1850: train=0.333333 test=0.333333
batch 1860: train=0.333333 test=0.333333
batch 1870: train=0.333333 test=0.333333
batch 1880: train=0.333333 test=0.333333
batch 1890: train=0.333333 test=0.333333
batch 1900: train=0.333333 test=0.333333
batch 1910: train=0.333333 test=0.333333
batch 1920: train=0.333333 test=0.333333
batch 1930: train=0.333333 test=0.333333
batch 1940: train=0.333333 test=0.333333
batch 1950: train=0.333333 test=0.333333
batch 1960: train=0.333333 test=0.333333
batch 1970: train=0.333333 test=0.333333Using TensorFlow backend.
/home/xuemeng/Proj/ChestMotion/ReadData.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  nda = np.array(data).shape[0]

batch 1980: train=0.333333 test=0.333333
batch 1990: train=0.333333 test=0.333333
personlist:['XueMeng', 'WuYuan', 'XZQ', 'QinDang', 'OuRunMin', 'ZhuTianLin', 'ZhuXiaoTian']
keys:['ZhuTianLin', 0, 0]
keys:['ZhuTianLin', 'XZQ', 0]
keys:['ZhuTianLin', 'XZQ', 'WuYuan']
45
135
<BatchDataset shapes: ((None, 2000, 39, 1), (None,)), types: (tf.float32, tf.float32)>
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
labels:[0. 1. 2.], preds:[0 0 0]
label:ZhuTianLin,  抽取出来的总次数:45,  其中预测正确的次数:45,  acc:100.0%
label:XZQ,  抽取出来的总次数:45,  其中预测正确的次数:0,  acc:0.0%
label:WuYuan,  抽取出来的总次数:45,  其中预测正确的次数:0,  acc:0.0%
